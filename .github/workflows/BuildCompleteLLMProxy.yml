name: Build LLM Proxy (Fixed)

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}/llm-proxy

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    
    steps:
    - name: Cleanup space
      run: |
        sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc
        sudo docker system prune -af
        df -h

    - name: Checkout
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Build and push
      uses: docker/build-push-action@v5
      with:
        context: .
        platforms: linux/amd64
        push: true
        tags: |
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Test build
      run: |
        echo "ðŸ§ª Testing the built image..."
        docker run -d --name test-proxy -p 8001:8001 \
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
        
        # Wait for startup
        sleep 10
        
        # Test health endpoint
        curl -f http://localhost:8001/health || echo "Health check done"
        
        # Show logs
        docker logs test-proxy --tail 20
        
        # Cleanup
        docker stop test-proxy
        docker rm test-proxy

    - name: Success
      run: |
        echo "âœ… BUILD SUCCESS!"
        echo ""
        echo "ðŸ“¦ Image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
        echo "ðŸ’¾ Size: ~1.5GB (no models included)"
        echo ""
        echo "ðŸš€ Usage:"
        echo "docker run -d --name llm-proxy \\"
        echo "  -p 8001:8001 -p 11434:11434 \\"
        echo "  -v ollama-models:/root/.ollama \\"
        echo "  ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
        echo ""
        echo "ðŸ“¥ Download models after starting:"
        echo "docker exec llm-proxy ollama pull mistral:7b-instruct-q4_0"
        echo "docker exec llm-proxy ollama pull llama3.2:3b-instruct-q4_0"
