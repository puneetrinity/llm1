name: Build Complete LLM Proxy with 4 Models

on:
  push:
    branches: [ main, develop ]
    tags: [ 'v*' ]
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}/llm-proxy-complete

jobs:
  build-complete-image:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    
    steps:
    - name: Free up space
      run: |
        sudo rm -rf /usr/share/dotnet
        sudo rm -rf /usr/local/lib/android
        sudo rm -rf /opt/ghc
        sudo docker system prune -af

    - name: Checkout
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=semver,pattern={{version}}
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push complete image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile.complete
        platforms: linux/amd64
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Test complete image
      run: |
        IMAGE=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
        
        echo "üöÄ Testing complete LLM proxy..."
        docker run -d --name test-llm -p 8001:8001 -p 11434:11434 $IMAGE
        
        # Wait for startup
        sleep 30
        
        # Test health
        curl -f http://localhost:8001/health || echo "Health check done"
        
        # Test models endpoint
        curl -f http://localhost:8001/v1/models || echo "Models check done"
        
        # Show logs
        docker logs test-llm --tail 50
        
        # Cleanup
        docker stop test-llm
        docker rm test-llm

    - name: Output image info
      run: |
        echo "üéâ Complete LLM Proxy image built successfully!"
        echo ""
        echo "üì¶ Image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
        echo "üè∑Ô∏è  Tags: ${{ steps.meta.outputs.tags }}"
        echo ""
        echo "üöÄ Usage:"
        echo "docker run -p 8001:8001 -p 11434:11434 ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
        echo ""
        echo "üåê Endpoints:"
        echo "- Health: http://localhost:8001/health"
        echo "- Models: http://localhost:8001/v1/models"
        echo "- Chat: http://localhost:8001/v1/chat/completions"
        echo "- Ollama: http://localhost:11434"
