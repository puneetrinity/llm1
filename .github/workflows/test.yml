name: Test Suite

# Event triggers
on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM

jobs:
  # Frontend tests
  frontend-tests:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        
    
    - name: Install frontend dependencies
      working-directory: frontend
      run: |
        npm ci --legacy-peer-deps
    
    - name: Run frontend tests
      working-directory: frontend
      run: |
        npm test -- --coverage --watchAll=false
    
    - name: Build frontend
      working-directory: frontend
      run: |
        npm run build

  # Python/Backend tests
  backend-tests:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio
    
    - name: Run Python tests
      run: |
        pytest tests/ --cov=. --cov-report=xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  # Docker build test
  docker-test:
    runs-on: ubuntu-latest
    needs: [frontend-tests, backend-tests]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build test image
      run: |
        docker build -t llm-proxy:test .
    
    - name: Run container tests
      run: |
        # Start container
        docker run -d --name test-llm-proxy \
          -p 8001:8001 \
          -e ENABLE_AUTH=false \
          -e ENABLE_SEMANTIC_CLASSIFICATION=false \
          -e MAX_MEMORY_MB=4096 \
          llm-proxy:test
        
        # Wait for startup
        sleep 60
        
        # Run comprehensive tests
        docker exec test-llm-proxy python3 -c "
        import requests
        import time
        
        # Test health endpoint
        response = requests.get('http://localhost:8001/health')
        assert response.status_code == 200
        print('✅ Health check passed')
        
        # Test API documentation
        response = requests.get('http://localhost:8001/docs')
        assert response.status_code == 200
        print('✅ API docs accessible')
        
        # Test chat completion endpoint
        response = requests.post('http://localhost:8001/v1/chat/completions', 
          json={
            'model': 'gpt-3.5-turbo',
            'messages': [{'role': 'user', 'content': 'Hello'}],
            'max_tokens': 5
          },
          headers={'X-API-Key': 'test-key'}
        )
        print(f'Chat API status: {response.status_code}')
        print('✅ All tests passed')
        "
        
        # Cleanup
        docker stop test-llm-proxy
        docker rm test-llm-proxy

  # Performance test
  performance-test:
    runs-on: ubuntu-latest
    needs: docker-test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Run performance tests
      run: |
        # Build and start container
        docker build -t llm-proxy:perf .
        docker run -d --name perf-test \
          -p 8001:8001 \
          -e ENABLE_AUTH=false \
          llm-proxy:perf
        
        sleep 60
        
        # Install load testing tools
        sudo apt-get update
        sudo apt-get install -y apache2-utils
        
        # Run load test
        ab -n 100 -c 10 http://localhost:8001/health
        
        # Cleanup
        docker stop perf-test
        docker rm perf-test
