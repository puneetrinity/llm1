version: '3.8'

services:
  llm-proxy:
    build:
      context: .
    container_name: llm-proxy-dev
    restart: unless-stopped
    ports:
      - "8001:8001"
      - "11434:11434"
    environment:
      - DEBUG=true
      - LOG_LEVEL=DEBUG
      - ENABLE_AUTH=false
      - ENABLE_SEMANTIC_CLASSIFICATION=true
      - MAX_MEMORY_MB=8192
    volumes:
      - .:/app
    depends_on:
      - redis

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
