name: Build Docker Image

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Print image info
      run: |
        echo "âœ… Docker image built and pushed successfully!"
        echo "ðŸ“¦ Image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
        echo ""
        echo "ðŸš€ To run locally:"
        echo "docker run -d --name llm-proxy -p 8001:8001 -p 11434:11434 ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
        echo ""
        echo "ðŸ“¥ Download models after starting:"
        echo "docker exec llm-proxy ollama pull mistral:7b-instruct-q4_0"
